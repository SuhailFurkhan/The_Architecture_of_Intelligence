# ğŸ§  AI Concepts Reference Hub

A Streamlit application for learning AI/ML from the ground up â€” from the Perceptron to Large Language Models â€” plus DevOps/Infrastructure tutorials.

## Structure

```
AI_Concepts_Application/
â”œâ”€â”€ .streamlit/config.toml              # Theme & Streamlit config
â”œâ”€â”€ topics/                             # Auto-discovered AI/ML topic modules
â”‚   â”œâ”€â”€ __init__.py                     # Auto-discovery engine
â”‚   â””â”€â”€ learning_path.py               # Starter: Perceptron â†’ LLM roadmap
â”œâ”€â”€ Implementation/                     # Concept implementations (from scratch)
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ Automation_Infrastructure/          # Docker, K8s, DevOps tutorials
â”‚   â”œâ”€â”€ __init__.py                     # Auto-discovery engine
â”‚   â”œâ”€â”€ _tutorial_template.py           # Template for new tutorials
â”‚   â”œâ”€â”€ docker_fundamentals.py          # Docker walkthrough
â”‚   â””â”€â”€ kubernetes_fundamentals.py      # K8s walkthrough
â”œâ”€â”€ Concept_breakdown/                  # Detailed notes & diagrams
â”œâ”€â”€ Required_Images/                    # Architecture visuals & diagrams
â”œâ”€â”€ app.py                              # Main Streamlit application
â”œâ”€â”€ LLM_module.py                       # AI assistant backend (Anthropic/OpenAI)
â”œâ”€â”€ SolutionGeneration.py               # Vision-based image analysis
â”œâ”€â”€ template.py                         # Template for new Implementation files
â”œâ”€â”€ requirements.txt                    # Python dependencies
â”œâ”€â”€ Keys.env                            # API keys (git-ignored)
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

## Quick Start

```bash
# 1. Create virtual environment
python -m venv .venv
source .venv/bin/activate   # or .venv\Scripts\activate on Windows

# 2. Install dependencies
pip install -r requirements.txt

# 3. Add your API key (optional, for AI Assistant)
# Edit Keys.env and add your ANTHROPIC_API_KEY

# 4. Run the app
streamlit run app.py
```

## 4 Main Sections

| Section | What it contains |
|---------|-----------------|
| ğŸ“š **Topics** | AI/ML theory from Perceptron to LLMs (auto-discovered from `topics/`) |
| ğŸ”¬ **Implement** | From-scratch implementations with math, code, visualizations (`Implementation/`) |
| ğŸ—ï¸ **Infra** | Docker, Kubernetes, DevOps tutorials (`Automation_Infrastructure/`) |
| ğŸ¤– **AI Help** | Chat with Claude/GPT about any concept |

## Adding Content

### Topics (AI/ML)
Create a `.py` file in `topics/` with `TOPIC_NAME`, `THEORY`, `COMPLEXITY`, `OPERATIONS`, `get_content()`. Auto-discovered on restart.

### Implementations
Copy `template.py` into `Implementation/`, add `Level:` and `Concepts:` metadata. The template includes 11 sections: overview, intuition, math, architecture, walkthrough, implementation, alternative, pitfalls, connections, demo, and references.

### Infrastructure Tutorials
Copy `Automation_Infrastructure/_tutorial_template.py`, rename without the underscore prefix, fill in `TOPIC_NAME`, `CATEGORY`, `THEORY`, `COMMANDS`, `OPERATIONS`. Auto-discovered on restart.

## AI Assistant
Supports Anthropic Claude, OpenAI GPT, and Mock mode. Add your API key to `Keys.env`.

Create a `Keys.env` file in the project root. The app will auto-detect whichever keys are present and pick the best available provider (Anthropic preferred over OpenAI).

```env
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Keys.env  â€”  API Keys for AI Concepts Reference Hub
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Rules:
#   â€¢ NO spaces around the = sign
#   â€¢ NO quotes around the value
#   â€¢ NO trailing spaces after the value
#   â€¢ Lines starting with # are comments and are ignored
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# Anthropic Claude  (preferred LLM provider)
# Get your key at: https://console.anthropic.com
# Format: starts with "sk-ant-api03-", exactly 108 characters
ANTHROPIC_API_KEY=sk-ant-xxxxx-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# OpenAI GPT  (fallback LLM provider)
# Get your key at: https://platform.openai.com/api-keys
# Format: starts with "sk-"
OPENAI_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# HuggingFace  (required for fine-tuning pipeline steps)
# Get your token at: https://huggingface.co/settings/tokens
# Format: starts with "hf_"
HF_TOKEN=hf_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

### Which keys do you need?

| Key                 | Required for                     | Where to get it                                                          |
|---------------------|----------------------------------|--------------------------------------------------------------------------|
| `ANTHROPIC_API_KEY` | AI Help chat (preferred)         | [console.anthropic.com](https://console.anthropic.com)                   |
| `OPENAI_API_KEY`    | AI Help chat (fallback)          | [platform.openai.com/api-keys](https://platform.openai.com/api-keys)     |
| `HF_TOKEN`          | Fine-tuning topic pipeline steps | [huggingface.co/settings/tokens](https://huggingface.co/settings/tokens) |

You only need **one** of `ANTHROPIC_API_KEY` or `OPENAI_API_KEY` for the AI assistant. 
If both are present the app automatically uses Anthropic. `HF_TOKEN` is only needed if you want to run the Full Fine-Tuning, PEFT Additive, or LoRA pipeline steps.

> âš ï¸ `Keys.env` is listed in `.gitignore` â€” it will never be committed to version control.


